{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_from_scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwvfPwGk4QtebGmNdHj0mZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhihong1224/RNN_demo/blob/master/RNN_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv73aOXZ64C5",
        "colab_type": "text"
      },
      "source": [
        "# 读取数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tffeoufAUnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozrXBfWr51E4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "4d5fc359-94a1-41f9-b8ce-9d16214317ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeaGzUpG7HYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d560a70d-d0e8-424d-a8b3-df6aad42b4f5"
      },
      "source": [
        "ROOT='gdrive/My Drive/Colab Notebooks/data'\n",
        "with zipfile.ZipFile(os.path.join(ROOT,'jaychou_lyrics.txt.zip')) as zin:\n",
        "  with zin.open('jaychou_lyrics.txt') as f:\n",
        "    corpus_chars=f.read().decode('utf-8')\n",
        "corpus_chars[:40]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'想要有直升机\\n想要和你飞到宇宙去\\n想要和你融化在一起\\n融化在宇宙里\\n我每天每天每'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXiyPoJT714X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_chars=corpus_chars.replace('\\n',' ').replace('\\r',' ')\n",
        "corpus_chars=corpus_chars[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mGGElCC8lm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "621effb8-d3a3-48b4-b815-74d7b7f5bb8a"
      },
      "source": [
        "corpus_chars[:40]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'想要有直升机 想要和你飞到宇宙去 想要和你融化在一起 融化在宇宙里 我每天每天每'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cglG2Fls8L85",
        "colab_type": "text"
      },
      "source": [
        "# 建立字符索引"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynAzoC1Z8JSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7d10f74-fd66-4d5b-ae3f-cb59117a95d7"
      },
      "source": [
        "idx_to_char=list(set(corpus_chars))\n",
        "print(len(idx_to_char))\n",
        "char_to_idx={char:idx for idx,char in enumerate(idx_to_char)}\n",
        "vocab_size=len(char_to_idx)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xSPo6kg8iF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e27da4fc-09cb-4bad-b147-f2a688720015"
      },
      "source": [
        "# 将训练数据中的每个字符转换为索引\n",
        "corpus_indices=[char_to_idx[char] for char in corpus_chars]\n",
        "sample=corpus_indices[:20]\n",
        "print('chars:',''.join(idx_to_char[idx] for idx in sample))\n",
        "print('indices:',sample)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chars: 想要有直升机 想要和你飞到宇宙去 想要和\n",
            "indices: [630, 787, 994, 555, 847, 410, 42, 630, 787, 371, 446, 249, 426, 759, 317, 682, 42, 630, 787, 371]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8KlmBad9Vpu",
        "colab_type": "text"
      },
      "source": [
        "# 时序数据采样"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K823aQc9DHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_data(corpus_indices,batch_size,seq_len):\n",
        "  # corpus_indices:列表\n",
        "  batch_len=len(corpus_indices)//batch_size\n",
        "  batch_num=(batch_len-1)//seq_len\n",
        "  all_data=torch.tensor(corpus_indices[:batch_len*batch_size]).view(batch_size,batch_len)\n",
        "  for i in range(batch_num):\n",
        "    x=all_data[:,i*seq_len:(i+1)*seq_len]\n",
        "    y=all_data[:,i*seq_len+1:(i+1)*seq_len+1]\n",
        "    yield x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMVltzak-t37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "5af83946-2f4f-495a-966e-ace76ce1c56d"
      },
      "source": [
        "mini_indices=range(30)\n",
        "batch_size=2\n",
        "seq_len=6\n",
        "dataset=sample_data(mini_indices,batch_size,seq_len)\n",
        "print(mini_indices)\n",
        "print()\n",
        "for X,Y in dataset:\n",
        "  print(X,Y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(0, 30)\n",
            "\n",
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [15, 16, 17, 18, 19, 20]]) tensor([[ 1,  2,  3,  4,  5,  6],\n",
            "        [16, 17, 18, 19, 20, 21]])\n",
            "tensor([[ 6,  7,  8,  9, 10, 11],\n",
            "        [21, 22, 23, 24, 25, 26]]) tensor([[ 7,  8,  9, 10, 11, 12],\n",
            "        [22, 23, 24, 25, 26, 27]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNDMqLI4AI7B",
        "colab_type": "text"
      },
      "source": [
        "# RNN from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsFIvanr_jZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one-hot向量\n",
        "def get_onehot(x,vocab_size):\n",
        "  # x: torch.tensor (batch_size,seq_len)\n",
        "  # vocab_size:len of vocab\n",
        "  bs,sq=x.shape\n",
        "  result=torch.zeros((bs,sq,vocab_size),device=x.device)\n",
        "  for i in range(bs):\n",
        "    for j in range(sq):\n",
        "      result[i,j,int(x[i,j])]=1\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ__HTWqG-KL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ccf1cbb1-7232-4517-b0ac-53f9a9179fd5"
      },
      "source": [
        "X=torch.arange(10).view(2,5)\n",
        "inputs=get_onehot(X,vocab_size)\n",
        "print(len(inputs),inputs[0].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 torch.Size([5, 1027])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwtJMAzVCbvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee8f79f6-19d7-44ff-b89a-916eb31df967"
      },
      "source": [
        "# 初始化模型参数\n",
        "num_inputs,num_hiddens,num_outputs=vocab_size,256,vocab_size\n",
        "print('will use',device)\n",
        "\n",
        "def get_params():\n",
        "  def _one(shape):\n",
        "    ts=torch.tensor(np.random.normal(0,0.01,size=shape),device=device,dtype=torch.float32)\n",
        "    return torch.nn.Parameter(ts,requires_grad=True)\n",
        "  \n",
        "  W_xh=_one((num_inputs,num_hiddens))\n",
        "  W_hh=_one((num_hiddens,num_hiddens))\n",
        "  W_hq=_one((num_hiddens,num_outputs))\n",
        "\n",
        "  b_h=torch.nn.Parameter(torch.zeros(num_hiddens,device=device),requires_grad=True)\n",
        "  b_q=torch.nn.Parameter(torch.zeros(num_outputs,device=device),requires_grad=True)\n",
        "  return torch.nn.ParameterList([W_xh,W_hh,b_h,W_hq,b_q])\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "will use cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DgWMwegCxSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义模型\n",
        "def init_rnn_state(batch_size,num_hiddens,device):\n",
        "  return torch.zeros((batch_size,num_hiddens),device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUw2N_4xEaaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn(inputs,state,params):\n",
        "  # inputs:(batch_size,seq_len,vocab_size)\n",
        "  # state:(batch_size,vocab_size)\n",
        "  # params:params\n",
        "\n",
        "  W_xh,W_hh,b_h,W_hq,b_q=params\n",
        "  H=state\n",
        "  bs,sq,v=inputs.shape\n",
        "  result=torch.zeros_like(inputs)\n",
        "  for i in range(sq):\n",
        "    X=inputs[:,i,:]  #(batch_size,vocab_size)\n",
        "    H=torch.tanh(torch.matmul(X,W_xh)+torch.matmul(H,W_hh)+b_h)\n",
        "    Y=torch.matmul(H,W_hq)+b_q\n",
        "    result[:,i,:]=Y\n",
        "  return result,H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INbo53paGXlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fcd4aaf1-2c1b-448d-c515-e03d711161fe"
      },
      "source": [
        "state=init_rnn_state(X.shape[0],num_hiddens,device)\n",
        "inputs=get_onehot(X.to(device),vocab_size)\n",
        "params=get_params()\n",
        "outputs,state_new=rnn(inputs,state,params)\n",
        "print(outputs.shape,state_new.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5, 1027]) torch.Size([2, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpnRG05DHu85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义预测函数\n",
        "def predict_rnn(prefix,num_chars,rnn,params,init_rnn_state,num_hiddens,vocab_size,\n",
        "    device,idx_to_char,char_to_idx):\n",
        "  output=[char_to_idx[prefix[0]]]\n",
        "  state=init_rnn_state(1,num_hiddens,device=device) \n",
        "  for i in range(num_chars):\n",
        "    x=get_onehot(torch.tensor([[output[-1]]],device=device),vocab_size)   # (1,1,vocab_size)\n",
        "    y,state=rnn(x,state,params) # y:(1,1,vocab_size)\n",
        "    if i<len(prefix)-1:\n",
        "      output.append(char_to_idx[prefix[i+1]])\n",
        "    else:\n",
        "      output.append(int(y[0].argmax(dim=-1).item()))\n",
        "  return ''.join([idx_to_char[idx] for idx in output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR0CScSlJLSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e535b8df-d362-4a68-af28-99737e8bf549"
      },
      "source": [
        "predict_rnn('分开',10,rnn,params,init_rnn_state,num_hiddens,vocab_size,device,idx_to_char,char_to_idx)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'分开碗它埋钩准喜分温逗'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54Cv-RsMCib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 裁剪梯度\n",
        "def grad_clipping(params,theta,device):\n",
        "  norm=torch.tensor([0.],device=device)\n",
        "  for param in params:\n",
        "    norm+=(param.grad.data**2).sum()\n",
        "  norm=norm.sqrt().item()\n",
        "  if norm>theta:\n",
        "    for param in params:\n",
        "      param.grad.data*=(theta/norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fL7YpC6M8LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练\n",
        "def train(rnn,get_params,init_rnn_state,sample_data,corpus_indices,batch_size,\n",
        "    seq_len,vocab_size,num_hiddens,num_chars,num_epochs,lr,clipping_theta,\n",
        "    pred_period,idx_to_char,char_to_idx):\n",
        "  criterion=nn.CrossEntropyLoss()\n",
        "  params=get_params()\n",
        "  optimizer=optim.Adam(params,lr=lr)\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    state=init_rnn_state(batch_size,num_hiddens,device=device)\n",
        "    train_loss,n=0.0,0\n",
        "    data_iter=sample_data(corpus_indices,batch_size,seq_len)\n",
        "    for X,Y in data_iter:\n",
        "      X=X.cuda()\n",
        "      Y=Y.cuda()\n",
        "      inputs=get_onehot(X,vocab_size)  #(batch_size,seq_len,vocab_size)\n",
        "      outputs,state=rnn(inputs,state,params) #output:(batch_size,seq_len,vocab_size)\n",
        "      outputs=outputs.view(-1,vocab_size) #(batch_size*seq_len,vocab_size)\n",
        "      y=Y.view(-1)\n",
        "      loss=criterion(outputs,y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      grad_clipping(params,clipping_theta,device)\n",
        "      optimizer.step()\n",
        "\n",
        "      if isinstance(state,tuple):\n",
        "        state=(state[0].detach(),state[1].detach())\n",
        "      else:\n",
        "        state=state.detach()\n",
        "\n",
        "      train_loss+=loss.item()*batch_size*seq_len\n",
        "      n+=y.shape[0]\n",
        "    if (epoch+1)%pred_period==0:\n",
        "      print('epoch:{},train loss:{}'.format(epoch+1,train_loss/n))\n",
        "      for prefix in prefixes:\n",
        "        print('-',predict_rnn(prefix,num_chars,rnn,params,init_rnn_state,num_hiddens,vocab_size,\n",
        "    device,idx_to_char,char_to_idx))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iifs8BVyQQXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs,seq_len,batch_size,lr,clipping_theta=250,35,32,0.003,1e-2\n",
        "num_chars=50\n",
        "pred_period,prefixes=50,['分开','不分开']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrByBMijRK99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "a1922987-bdf5-4567-9c4e-2baf1184bd6a"
      },
      "source": [
        "train(rnn,get_params,init_rnn_state,sample_data,corpus_indices,batch_size,\n",
        "    seq_len,vocab_size,num_hiddens,num_chars,num_epochs,lr,clipping_theta,\n",
        "    pred_period,idx_to_char,char_to_idx)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:50,train loss:5.2139909863471985\n",
            "- 分开 我我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的\n",
            "- 不分开 我我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我\n",
            "epoch:50,train loss:5.2139909863471985\n",
            "- 分开 我我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的\n",
            "- 不分开 我我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我的我  我\n",
            "epoch:100,train loss:4.3746888637542725\n",
            "- 分开 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 \n",
            "- 不分开 我不么的可爱 我的让我你你的可爱 我的让我你你的可爱 我的让我你你的可爱 我的让我你你的可爱 \n",
            "epoch:100,train loss:4.3746888637542725\n",
            "- 分开 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 我不么 我 \n",
            "- 不分开 我不么的可爱 我的让我你你的可爱 我的让我你你的可爱 我的让我你你的可爱 我的让我你你的可爱 \n",
            "epoch:150,train loss:3.6700417697429657\n",
            "- 分开 你你着我 我不能的可爱女人 我不了我 我不是我不想的可爱女人 我不了我  在一场的人 我不能我不\n",
            "- 不分开 我不么的可爱女人 我不了我  在一起的可爱女人 我不了我  在一起 我不能 我不要你的想你你想\n",
            "epoch:150,train loss:3.6700417697429657\n",
            "- 分开 你你着我 我不能的可爱女人 我不了我 我不是我不想的可爱女人 我不了我  在一场的人 我不能我不\n",
            "- 不分开 我不么的可爱女人 我不了我  在一起的可爱女人 我不了我  在一起 我不能 我不要你的想你你想\n",
            "epoch:200,train loss:3.05916228890419\n",
            "- 分开 你牵着  想要你 一子我 我不能 我 我不着我 我不能的让我的可不可爱 不要你的想我不想 我不能\n",
            "- 不分开 我不能我不多 我 一直么  不是我不想的可爱女人 我不了我  在一个人 一枝杨柳 我不要再想 \n",
            "epoch:200,train loss:3.05916228890419\n",
            "- 分开 你牵着  想要你 一子我 我不能 我 我不着我 我不能的让我的可不可爱 不要你的想我不想 我不能\n",
            "- 不分开 我不能我不多 我 一直么  不是我不想的可爱女人 我不了我  在一个人 一枝杨柳 我不要再想 \n",
            "epoch:250,train loss:2.2740705609321594\n",
            "- 分开 一定么 一步两步三步四步望著天 看星星 一颗两颗三颗四颗 连成线背著背默默许下心愿 在小村外的溪\n",
            "- 不分开 我不能我不多 我 一直着我 我不能 我不要再想你 我不放开  想要你的手不放开  想样你想你你\n",
            "epoch:250,train loss:2.2740705609321594\n",
            "- 分开 一定么 一步两步三步四步望著天 看星星 一颗两颗三颗四颗 连成线背著背默默许下心愿 在小村外的溪\n",
            "- 不分开 我不能我不多 我 一直着我 我不能 我不要再想你 我不放开  想要你的手不放开  想样你想你你\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-UWq88tVKE7",
        "colab_type": "text"
      },
      "source": [
        "# GRU from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NunP6UE5RN0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 参数初始化\n",
        "def get_params():\n",
        "  def _one(shape):\n",
        "    ts=torch.tensor(np.random.normal(0,0.01,shape),device=device,dtype=torch.float32)\n",
        "    return torch.nn.Parameter(ts,requires_grad=True)\n",
        "  def _three():\n",
        "    return (_one((num_inputs,num_hiddens)),\n",
        "        _one((num_hiddens,num_hiddens)),\n",
        "        torch.nn.Parameter(torch.zeros(num_hiddens,device=device,dtype=torch.float32),requires_grad=True))\n",
        "  W_xz,W_hz,b_z=_three()\n",
        "  W_xr,W_hr,b_r=_three()\n",
        "  W_xh,W_hh,b_h=_three()\n",
        "\n",
        "  W_hq=_one((num_hiddens,num_outputs))\n",
        "  b_q=torch.nn.Parameter(torch.zeros(num_outputs,device=device,dtype=torch.float32),requires_grad=True)\n",
        "  return torch.nn.ParameterList([W_xz,W_hz,b_z,W_xr,W_hr,b_r,W_xh,W_hh,b_h,W_hq,b_q])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CSPN6I6YmMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初始化隐藏状态\n",
        "def init_gru_state(batch_size,num_hiddens,device):\n",
        "  return torch.zeros((batch_size,num_hiddens),device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z1UH3qsYf8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义模型\n",
        "def gru(inputs,state,params):\n",
        "  # inputs:(batch_size,seq_len,vocab_size)\n",
        "  # state:(batch_size,num_hiddens)\n",
        "  W_xz,W_hz,b_z,W_xr,W_hr,b_r,W_xh,W_hh,b_h,W_hq,b_q=params\n",
        "  H=state\n",
        "  bs,sq,v=inputs.shape\n",
        "  results=torch.zeros((bs,sq,v),device=device)\n",
        "  for i in range(sq):\n",
        "    X=inputs[:,i,:] #(bs,vocab_size)\n",
        "    Z=torch.sigmoid(torch.matmul(X,W_xz)+torch.matmul(H,W_hz)+b_z)\n",
        "    R=torch.sigmoid(torch.matmul(X,W_xr)+torch.matmul(H,W_hr)+b_r)\n",
        "    H_tilda=torch.tanh(torch.matmul(X,W_xh)+torch.matmul(R*H,W_hh)+b_h)\n",
        "    H=Z*H+(1-Z)*H_tilda\n",
        "    Y=torch.matmul(H,W_hq)+b_q   #(batch_size,vocab_size)\n",
        "    results[:,i,:]=Y   \n",
        "  return results,H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPZW3u9ybciK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#训练\n",
        "num_epochs,seq_len,batch_size,lr,clipping_theta=160,35,32,0.003,1e-2\n",
        "pred_period,num_chars,prefixes=40,50,['分开','不分开']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TblBfbGbt37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "3effd8d0-7b53-4f63-b367-f6019fb4c495"
      },
      "source": [
        "train(gru,get_params,init_gru_state,sample_data,corpus_indices,batch_size,\n",
        "    seq_len,vocab_size,num_hiddens,num_chars,num_epochs,lr,clipping_theta,\n",
        "    pred_period,idx_to_char,char_to_idx)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:40,train loss:0.5922007896006107\n",
            "- 分开始打我 别怪我 别怪我 别怪我 别怪我 别怪我 别怪我 别怪我 别怪我 别怪我 别怪我 别怪我 别\n",
            "- 不分开 不知不觉 我不能再想 我不要再想 我不 我不 我不能再想 我不 我不 我不能再想 我不 我不 \n",
            "epoch:80,train loss:0.02615923178382218\n",
            "- 分开 一场悲剧 我的人在抽屉 它所拥有的只剩下回忆 相爱还有别离 像无法被安排的雨 随时准备来袭 我怀\n",
            "- 不分开  它一直在身边 干什么 干什么 我打开任督二脉 干什么 干什么 东亚病夫的招牌 干什么 干什么\n",
            "epoch:120,train loss:0.01577853853814304\n",
            "- 分开 在小村外的溪边河口默默等著我 娘子依旧每日折一枝杨柳 你在那里 在小村外的溪边 默默等待 娘子 \n",
            "- 不分开 爱情来的太快就像龙卷风 离不开暴风圈来不及逃 我不能再想 我不能再想 我不 我不 我不能 爱情\n",
            "epoch:160,train loss:0.01548444724176079\n",
            "- 分开 在小村外的溪边 默默等待 娘子 有什么不妥 有话就直说 别窝在角落 不爽就反驳 到底拽什么 懂不\n",
            "- 不分开 爱能 到你一口 随风跟著我 一口一口吃掉忧愁 载著你 彷彿载著阳光 不管到哪里都是晴天 蝴蝶自\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QetSWLPcCTvA",
        "colab_type": "text"
      },
      "source": [
        "# LSTM from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM62jXG8b7la",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a353926-0e7f-46b9-cf55-e273b6c59f01"
      },
      "source": [
        "num_inputs,num_hiddens,num_outputs=vocab_size,256,vocab_size\n",
        "device=torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "print('will use',device)\n",
        "\n",
        "def get_params():\n",
        "  def _one(shape):\n",
        "    ts=torch.tensor(np.random.normal(0,0.01,size=shape),device=device,dtype=torch.float32)\n",
        "    return torch.nn.Parameter(ts,requires_grad=True)\n",
        "  def _three():\n",
        "    return (_one((num_inputs,num_hiddens)),\n",
        "        _one((num_hiddens,num_hiddens)),\n",
        "        torch.nn.Parameter(torch.zeros(num_hiddens,device=device,dtype=torch.float32),\n",
        "              requires_grad=True))\n",
        "  W_xi,W_hi,b_i=_three()\n",
        "  W_xo,W_ho,b_o=_three()\n",
        "  W_xf,W_hf,b_f=_three()\n",
        "  W_xc,W_hc,b_c=_three()\n",
        "\n",
        "  W_hq=_one((num_hiddens,num_outputs))\n",
        "  b_q=torch.nn.Parameter(torch.zeros(num_outputs,device=device,dtype=torch.float32),requires_grad=True)\n",
        "  return nn.ParameterList([W_xi,W_hi,b_i,W_xo,W_ho,b_o,W_xf,W_hf,b_f,W_xc,W_hc,b_c,W_hq,b_q])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "will use cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HASQGg8tFo0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初始化隐藏状态\n",
        "def init_lstm_state(batch_size,num_hiddens,device):\n",
        "  return (torch.zeros((batch_size,num_hiddens),device=device),\n",
        "      torch.zeros((batch_size,num_hiddens),device=device))\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw04cCYfGWEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义模型\n",
        "def lstm(inputs,state,params):\n",
        "  # inputs:(batch_size,seq_len,vocab_size)\n",
        "  # state:(H,C) (batch_size,num_hiddens)\n",
        "  W_xi,W_hi,b_i,W_xo,W_ho,b_o,W_xf,W_hf,b_f,W_xc,W_hc,b_c,W_hq,b_q=params\n",
        "  (H,C)=state\n",
        "  bs,sq,v=inputs.shape\n",
        "  results=torch.zeros((bs,sq,v),device=inputs.device)\n",
        "  for i in range(sq):\n",
        "    X=inputs[:,i,:]   #(batch_size,vocab_size)\n",
        "    I=torch.sigmoid(torch.matmul(X,W_xi)+torch.matmul(H,W_hi)+b_i)\n",
        "    O=torch.sigmoid(torch.matmul(X,W_xo)+torch.matmul(H,W_ho)+b_o)\n",
        "    F=torch.sigmoid(torch.matmul(X,W_xf)+torch.matmul(H,W_hf)+b_f)\n",
        "    C_tilda=torch.tanh(torch.matmul(X,W_xc)+torch.matmul(H,W_hc)+b_c)\n",
        "    C=I*C_tilda+F*C\n",
        "    H=O*torch.tanh(C)\n",
        "    Y=torch.matmul(H,W_hq)+b_q\n",
        "    results[:,i,:]=Y\n",
        "  return results,(H,C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD-mwjgyIR4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练模型\n",
        "num_epochs,seq_len,batch_size,lr,clipping_theta=160,35,32,0.003,1e-2\n",
        "pred_period,num_chars,prefixes=40,50,['分开','不分开']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdwnAaJyIkNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "1aec64af-9e87-495a-d487-51b38439750e"
      },
      "source": [
        "train(lstm,get_params,init_lstm_state,sample_data,corpus_indices,batch_size,\n",
        "    seq_len,vocab_size,num_hiddens,num_chars,num_epochs,lr,clipping_theta,\n",
        "    pred_period,idx_to_char,char_to_idx)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:40,train loss:3.46826308965683\n",
            "- 分开始的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的\n",
            "- 不分开始不觉 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不\n",
            "epoch:80,train loss:1.8293461501598358\n",
            "- 分开始的见 我想要你的见 我想要你这样打我妈妈 你想你的让我妈妈 你想要你 想要你 想要你 想要你 想\n",
            "- 不分开始的见 我不能再想 我不要再想 我不要再想 我不能再想 我不能再想 我不能再想 我不能再想 我不\n",
            "epoch:120,train loss:0.8255559429526329\n",
            "- 分开始的爸 心伤透明的我面开我 爱过苏美女人 透明的让我感动的可爱女人 坏坏的让我疯狂的可爱女人 坏坏\n",
            "- 不分开始的微 从小的钟  纪录第一次遇见的你 说你看着我 开始球口 相给还的可以 我给你的可爱女人 坏\n",
            "epoch:160,train loss:0.3391432352364063\n",
            "- 分开始的爸  说下午三三四四  回忆的的字迹依然清晰可见 我给你的爱写在西元前 深埋在美索不达米亚平原\n",
            "- 不分开始的脸 祭司 神殿 征战 弓箭 是谁的从前 喜欢在人切记 盲无能为力再提起 决定中断熟悉 然后在\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7SExD_wJToL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}