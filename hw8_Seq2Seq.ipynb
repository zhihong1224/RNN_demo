{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw8_Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LIjdELJM3gBE",
        "q3FFxvndGgtL",
        "GLFb1kGKKxJU",
        "RmXoEmMwlICa",
        "Xm5LjfHFlKvg",
        "kCFVQtoJpDN0",
        "TvGjSMfi1VH3"
      ],
      "authorship_tag": "ABX9TyNXdR+UuXc/jtQcpk5qbPHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhihong1224/RNN_demo/blob/master/hw8_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkTE-X_G1IeT",
        "colab_type": "text"
      },
      "source": [
        "# 1 MXNet 数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIjdELJM3gBE",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 MXNet 实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3FFxvndGgtL",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1 读取和预处理数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCEK6aI4GYpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import io\n",
        "import math\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "import torch.nn.functional as F\n",
        "import torchtext.vocab as Vocab\n",
        "import torch.utils.data as Data\n",
        "import sys\n",
        "\n",
        "PAD,BOS,EOS='<pad>','<bos>','<eos>'\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-jCxQpOIjLJ",
        "colab_type": "code",
        "outputId": "573279fb-c1c3-4e81-8f45-aee42c4d2f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFrEXNZFHLdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_one_seq(seq_tokens,all_tokens,all_seqs,max_seq_len):\n",
        "  all_tokens.extend(seq_tokens)\n",
        "  seq_tokens+=[EOS]+[PAD]*(max_seq_len-len(seq_tokens)-1)\n",
        "  all_seqs.append(seq_tokens)\n",
        "\n",
        "def build_data(all_tokens,all_seqs):\n",
        "  vocab=Vocab.Vocab(collections.Counter(all_tokens),specials=[PAD,BOS,EOS])\n",
        "  indices=[[vocab.stoi[w] for w in seq] for seq in all_seqs]\n",
        "  return vocab,torch.tensor(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y-AFK6XISuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT='drive/My Drive/Colab Notebooks/MXNet/MX_data'\n",
        "def read_data(max_seq_len):\n",
        "  in_tokens,out_tokens,in_seqs,out_seqs=[],[],[],[]\n",
        "  with open(os.path.join(ROOT,'fr-en-small.txt')) as f:\n",
        "    lines=f.readlines()\n",
        "  for line in lines:\n",
        "    in_seq,out_seq=line.rstrip().split('\\t')\n",
        "    in_seq_tokens,out_seq_tokens=in_seq.split(' '),out_seq.split(' ')\n",
        "    if max(len(in_seq_tokens),len(out_seq_tokens))>max_seq_len-1:\n",
        "      continue\n",
        "    process_one_seq(in_seq_tokens,in_tokens,in_seqs,max_seq_len)\n",
        "    process_one_seq(out_seq_tokens,out_tokens,out_seqs,max_seq_len)\n",
        "  in_vocab,in_data=build_data(in_tokens,in_seqs)\n",
        "  out_vocab,out_data=build_data(out_tokens,out_seqs)\n",
        "  return in_vocab,out_vocab,Data.TensorDataset(in_data,out_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NE6jr62KWq5",
        "colab_type": "code",
        "outputId": "4d423da4-67e4-4032-ac8f-c90169056b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_seq_len=7\n",
        "in_vocab,out_vocab,dataset=read_data(max_seq_len)\n",
        "dataset[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 5,  4, 45,  3,  2,  0,  0]), tensor([ 8,  4, 27,  3,  2,  0,  0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLFb1kGKKxJU",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2 含注意力机制的编码器-解码器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUHQbTg5KeUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 编码器\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,drop_prob=0,**kwargs):\n",
        "    super(Encoder,self).__init__(**kwargs)\n",
        "    self.embedding=nn.Embedding(vocab_size,embed_size)\n",
        "    self.rnn=nn.GRU(embed_size,num_hiddens,num_layers,dropout=drop_prob)\n",
        "  \n",
        "  def forward(self,inputs,state):\n",
        "    # inputs:(n,seq_len)\n",
        "    embedding=self.embedding(inputs.long()).permute(1,0,2)  #(seq_len,n,embed_size)\n",
        "    return self.rnn(embedding,state)\n",
        "\n",
        "  def begin_state(self):\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLOpssi0M2UW",
        "colab_type": "code",
        "outputId": "5e8ce456-8a75-47c0-9b16-abf850b1a99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 测试编码器输入输出\n",
        "encoder=Encoder(vocab_size=10,embed_size=8,num_hiddens=16,num_layers=2)\n",
        "output,state=encoder(torch.zeros((4,7)),encoder.begin_state())\n",
        "print(output.shape,state.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 4, 16]) torch.Size([2, 4, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDJONnZzNrEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 注意力机制\n",
        "def attention_model(input_size,attention_size):\n",
        "  model=nn.Sequential(\n",
        "    nn.Linear(input_size,attention_size,bias=False),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(attention_size,1,bias=False)\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuV6hehdRZAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention_forward(model,enc_states,dec_state):\n",
        "  # enc_states:(seq_len,n,num_hiddens)\n",
        "  # dec_states:(n,num_hiddens)\n",
        "  dec_states=dec_state.unsqueeze(dim=0).expand_as(enc_states)\n",
        "  enc_and_dec_states=torch.cat((enc_states,dec_states),dim=2) #(seq_len,n,2*num_hiddens)\n",
        "  e=model(enc_and_dec_states)  #(seq_len,n,1)\n",
        "  alpha=F.softmax(e,dim=0) #(seq_len,n,1)\n",
        "  return (alpha*enc_states).sum(dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k5TjqJBStrz",
        "colab_type": "code",
        "outputId": "d49bbdae-7491-4222-8b71-91b3d167e4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 测试注意力机制\n",
        "seq_len,batch_size,num_hiddens=10,4,8\n",
        "model=attention_model(2*num_hiddens,10)\n",
        "enc_states=torch.zeros((seq_len,batch_size,num_hiddens))\n",
        "dec_state=torch.zeros((batch_size,num_hiddens))\n",
        "attention_forward(model,enc_states,dec_state).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUEZkY16Txtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 含注意力机制的解码器\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,attention_size,drop_prob=0):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embed_size)\n",
        "    self.attention=attention_model(2*num_hiddens,attention_size)\n",
        "    self.rnn=nn.GRU(num_hiddens+embed_size,num_hiddens,num_layers,dropout=drop_prob)\n",
        "    self.out=nn.Linear(num_hiddens,vocab_size)\n",
        "  \n",
        "  def forward(self,cur_input,state,enc_states):\n",
        "    # cur_input:(n,)\n",
        "    # state:(num_layers,n,num_hiddens)\n",
        "    c=attention_forward(self.attention,enc_states,state[-1]) #(n,num_hiddens)\n",
        "    input_and_c=torch.cat((self.embedding(cur_input),c),dim=1) #(n,embed_size+num_hiddens)\n",
        "    output,state=self.rnn(input_and_c.unsqueeze(0),state)\n",
        "    output=self.out(output).squeeze(dim=0)\n",
        "    return output,state\n",
        "  \n",
        "  def begin_state(self,enc_state):\n",
        "    return enc_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmXoEmMwlICa",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.3 带mask的损失函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ntA-F6-gfr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 损失函数\n",
        "def batch_loss(encoder,decoder,X,Y,loss):\n",
        "  batch_size=X.shape[0]\n",
        "  enc_state=encoder.begin_state()\n",
        "  enc_outputs,enc_state=encoder(X,enc_state)\n",
        "  dec_state=decoder.begin_state(enc_state)\n",
        "  dec_input=torch.tensor([out_vocab.stoi[BOS]]*batch_size).cuda()\n",
        "  mask,num_not_pad_tokens=torch.ones(batch_size,).cuda(),0\n",
        "  l=torch.tensor([0.]).cuda()\n",
        "  for y in Y.permute(1,0):\n",
        "    dec_output,dec_state=decoder(dec_input,dec_state,enc_outputs)\n",
        "    l=l+(mask*loss(dec_output,y)).sum()\n",
        "    dec_input=y\n",
        "    num_not_pad_tokens+=mask.sum().item()\n",
        "    mask=mask*(y!=out_vocab.stoi[PAD]).float()\n",
        "  return l/num_not_pad_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm5LjfHFlKvg",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.4 模型训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYbfZ2rNlEhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(encoder,decoder,dataset,lr,batch_size,num_epochs):\n",
        "  encoder=encoder.cuda()\n",
        "  decoder=decoder.cuda()\n",
        "  enc_optimizer=optim.Adam(encoder.parameters(),lr=lr)\n",
        "  dec_optimizer=optim.Adam(decoder.parameters(),lr=lr)\n",
        "\n",
        "  loss=nn.CrossEntropyLoss()\n",
        "  data_iter=Data.DataLoader(dataset,batch_size,shuffle=True)\n",
        "  for epoch in range(num_epochs):\n",
        "    l_sum=0.\n",
        "    for X,Y in data_iter:\n",
        "      X=X.cuda()\n",
        "      Y=Y.cuda()\n",
        "      enc_optimizer.zero_grad()\n",
        "      dec_optimizer.zero_grad()\n",
        "      l=batch_loss(encoder,decoder,X,Y,loss)\n",
        "      l.backward()\n",
        "      enc_optimizer.step()\n",
        "      dec_optimizer.step()\n",
        "      l_sum+=l.item()\n",
        "    if (epoch+1)%10==0:\n",
        "      print('epoch %d,loss %.3f'%(epoch+1,l_sum/len(data_iter)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfsnx5USmHEG",
        "colab_type": "code",
        "outputId": "d1c0b6c2-6f18-4fe3-c0da-3f32ccd28bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "embed_size,num_hiddens,num_layers=64,64,2\n",
        "attention_size,drop_prob,lr,batch_size,num_epochs=10,0.5,0.01,2,50\n",
        "encoder=Encoder(len(in_vocab),embed_size,num_hiddens,num_layers,drop_prob)\n",
        "decoder=Decoder(len(out_vocab),embed_size,num_hiddens,num_layers,attention_size,drop_prob)\n",
        "train(encoder,decoder,dataset,lr,batch_size,num_epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 10,loss 0.395\n",
            "epoch 20,loss 0.173\n",
            "epoch 30,loss 0.127\n",
            "epoch 40,loss 0.037\n",
            "epoch 50,loss 0.033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCFVQtoJpDN0",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.5 预测不定长的序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucnSknolmj-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(encoder,decoder,input_seq,max_seq_len):\n",
        "  in_tokens=input_seq.split(' ')\n",
        "  in_tokens+=[EOS]+[PAD]*(max_seq_len-len(in_tokens)-1)\n",
        "  enc_input=torch.tensor([[in_vocab.stoi[tk] for tk in in_tokens]]).cuda()\n",
        "  enc_state=encoder.begin_state()\n",
        "  enc_output,enc_state=encoder(enc_input,enc_state)\n",
        "  dec_input=torch.tensor([out_vocab.stoi[BOS]]).cuda()\n",
        "  dec_state=decoder.begin_state(enc_state)\n",
        "  output_tokens=[]\n",
        "  for _ in range(max_seq_len):\n",
        "    dec_output,dec_state=decoder(dec_input,dec_state,enc_output)\n",
        "    pred=dec_output.argmax(dim=1)\n",
        "    pred_token=out_vocab.itos[int(pred.item())]\n",
        "    if pred_token==EOS:\n",
        "      break\n",
        "    else:\n",
        "      output_tokens.append(pred_token)\n",
        "      dec_input=pred\n",
        "  return output_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSh-RBFKqGPI",
        "colab_type": "code",
        "outputId": "dde98a86-661d-47e7-a9ab-a2ae3d38dbdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_seq='ils regardent .'\n",
        "translate(encoder,decoder,input_seq,max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['they', 'are', 'watching', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvGjSMfi1VH3",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.6 BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3HzC6bTqN2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bleu(pred_tokens,label_tokens,k):\n",
        "  len_pred,len_label=len(pred_tokens),len(label_tokens)\n",
        "  score=math.exp(min(0,1-len_label/len_pred))\n",
        "  for n in range(1,k+1):\n",
        "    num_matches,label_subs=0,collections.defaultdict(int)\n",
        "    for i in range(len_label-n+1):\n",
        "      label_subs[''.join(label_tokens[i:i+n])]+=1\n",
        "    for i in range(len_pred-n+1):\n",
        "      if label_subs[''.join(pred_tokens[i:i+n])]>0:\n",
        "        num_matches+=1\n",
        "        label_subs[''.join(pred_tokens[i:i+n])]-=1\n",
        "    score*=math.pow(num_matches/(len_pred-n+1),math.pow(0.5,n))\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgxuPU282WFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score(input_seq,label_seq,k):\n",
        "  pred_tokens=translate(encoder,decoder,input_seq,max_seq_len)\n",
        "  label_tokens=label_seq.split(' ')\n",
        "  print('bleu %.3f,predict:%s'%(bleu(pred_tokens,label_tokens,k),' '.join(pred_tokens)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUK-pP2U2uLw",
        "colab_type": "code",
        "outputId": "a90dcf5f-0ad0-4344-ca73-ed267618fa53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score('ils regardent .','they are watching .',k=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bleu 1.000,predict:they are watching .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZEuzyXy20FV",
        "colab_type": "code",
        "outputId": "04f3a647-6a95-4665-b4a8-8b796751bd2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score('ils sont canadiens .','they are canadian .',k=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bleu 0.658,predict:they are actors .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHpNrJc63GDI",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 自己实现Seq2Seq & attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvolplbzZ_Yb",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 读取并处理数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwtGnzTT3BeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 读入并处理数据\n",
        "BOS,EOS,PAD='<bos>','<eos>','<pad>'\n",
        "def get_data(filename):\n",
        "  in_lines,out_lines,in_tokens,out_tokens=[],[],[],[]\n",
        "  max_in_len,max_out_len=0,0\n",
        "  with open(filename) as f:\n",
        "    lines=f.readlines()\n",
        "  for line in lines:\n",
        "    line=line.rstrip().split('\\t')\n",
        "    in_line=line[0].split(' ')\n",
        "    out_line=line[1].split(' ')\n",
        "    in_tokens.extend(in_line)\n",
        "    out_tokens.extend(out_line)\n",
        "    in_lines.append(in_line)\n",
        "    out_lines.append(out_line)\n",
        "    if len(in_line)>max_in_len:\n",
        "      max_in_len=len(in_line)\n",
        "    if len(out_line)>max_out_len:\n",
        "      max_out_len=len(out_line)\n",
        "  max_in_len+=1\n",
        "  max_out_len+=1\n",
        "  for i in range(len(in_lines)):\n",
        "    in_lines[i]+=[EOS]+[PAD]*(max_in_len-1-len(in_lines[i]))\n",
        "    out_lines[i]+=[EOS]+[PAD]*(max_out_len-1-len(out_lines[i]))\n",
        "  return in_lines,out_lines,in_tokens,out_tokens,max_in_len,max_out_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V18qmY_japi3",
        "colab_type": "code",
        "outputId": "b6630867-39cd-4606-a06d-b0bad1cb07f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "ROOT='drive/My Drive/Colab Notebooks/MXNet/MX_data'\n",
        "filename=os.path.join(ROOT,'fr-en-small.txt')\n",
        "in_lines,out_lines,in_tokens,out_tokens,max_in_len,max_out_len=get_data(filename)\n",
        "print(in_lines[0],out_lines[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['elle', 'est', 'vieille', '.', '<eos>', '<pad>', '<pad>'] ['she', 'is', 'old', '.', '<eos>', '<pad>', '<pad>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swQdRG20bQSS",
        "colab_type": "code",
        "outputId": "671839a1-46aa-435d-e5eb-5839cbb3ca2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 创建字典\n",
        "in_vocab=Vocab.Vocab(collections.Counter(in_tokens),specials=[EOS,BOS,PAD])\n",
        "out_vocab=Vocab.Vocab(collections.Counter(out_tokens),specials=[EOS,BOS,PAD])\n",
        "print(len(in_vocab),len(out_vocab))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LqMkPeZboom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将句子转换为corpus\n",
        "def get_corpus(in_lines,out_lines,in_vocab,out_vocab):\n",
        "  in_corpus,out_corpus=[],[]\n",
        "  for i in range(len(in_lines)):\n",
        "    in_corpus.append([in_vocab.stoi[w] for w in in_lines[i]])\n",
        "    out_corpus.append([out_vocab.stoi[w] for w in out_lines[i]])\n",
        "  return torch.tensor(in_corpus),torch.tensor(out_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGkiZOkWcS2c",
        "colab_type": "code",
        "outputId": "df9d592b-46c0-4d72-d2a4-97b6385f95d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "in_corpus,out_corpus=get_corpus(in_lines,out_lines,in_vocab,out_vocab)\n",
        "print(in_corpus.shape,out_corpus.shape,in_corpus[0],out_corpus[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 7]) torch.Size([20, 7]) tensor([ 5,  4, 45,  3,  0,  2,  2]) tensor([ 8,  4, 27,  3,  0,  2,  2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UcySq3_wWl-",
        "colab_type": "code",
        "outputId": "6b5e3834-764d-4244-94df-85c163b442d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset=Data.TensorDataset(in_corpus,out_corpus)\n",
        "dataset[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 5,  4, 45,  3,  0,  2,  2]), tensor([ 8,  4, 27,  3,  0,  2,  2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcR4qUVicw8v",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 编码器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahk8qAVIcweg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,drop_prob=0.5):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embed_size)\n",
        "    self.rnn=nn.GRU(embed_size,num_hiddens,num_layers,batch_first=True,dropout=drop_prob)\n",
        "  \n",
        "  def forward(self,x,state):\n",
        "    # x:(batch_size,seq_len)\n",
        "    embed=self.embedding(x.long())  #(batch_size,seq_len,embed_size)\n",
        "    output,state=self.rnn(embed,state) #output:(batch_size,seq_len,num_hiddens) state:(num_layers,batch_size,num_hiddens)\n",
        "    return output,state\n",
        "\n",
        "  def begin_state(self):\n",
        "    return None "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it_vVt79csqB",
        "colab_type": "code",
        "outputId": "ffb500d6-e4bf-4823-ef45-d2a0038cd236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 测试编码器输入输出\n",
        "batch_size=3\n",
        "seq_len=8\n",
        "vocab_size,embed_size,num_hiddens,num_layers=40,10,16,2\n",
        "encoder=Encoder(vocab_size,embed_size,num_hiddens,num_layers).cuda()\n",
        "x=torch.zeros((batch_size,seq_len)).cuda()\n",
        "state=encoder.begin_state()\n",
        "enc_outputs,enc_state=encoder(x,state)\n",
        "print(enc_outputs.shape,enc_state.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 8, 16]) torch.Size([2, 3, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwAcbAQef0TM",
        "colab_type": "text"
      },
      "source": [
        "# 1.2.3 带注意力机制的解码器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIKjVCT6ctKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,attention_size,drop_prob=0.5):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embed_size)\n",
        "    self.rnn=nn.GRU(embed_size+num_hiddens,num_hiddens,num_layers,batch_first=True,dropout=drop_prob)\n",
        "    self.attention=nn.Sequential(\n",
        "      nn.Linear(2*num_hiddens,attention_size),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(attention_size,1)\n",
        "    )\n",
        "    self.fc=nn.Linear(num_hiddens,vocab_size)\n",
        "    self.vocab_size=vocab_size\n",
        "\n",
        "  def forward(self,x,state,enc_outputs):\n",
        "    # x:(batch_size,seq_len)\n",
        "    # state:(num_layers,batch_size,num_hiddens)\n",
        "    # enc_outputs:(batch_size,seq_len,num_hiddens)\n",
        "    output=torch.zeros((batch_size,x.shape[1],self.vocab_size)).cuda()\n",
        "    x_step=torch.tensor([out_vocab.stoi[BOS]]*batch_size).cuda() #(batch_size,)\n",
        "    for i in range(x.shape[1]):\n",
        "      embed_step=self.embedding(x_step.long())  #(batch_size,embed_size)\n",
        "      h=state[-1]  #(batch_size,num_hiddens)\n",
        "      h_expand=h.unsqueeze(dim=1).expand_as(enc_outputs) #(batch_size,seq_len,num_hiddens)\n",
        "      enc_and_h=torch.cat((enc_outputs,h_expand),dim=2) #(batch_size,seq_len,2*num_hiddens)\n",
        "      alpha=F.softmax(self.attention(enc_and_h),dim=1) #(batch_size,seq_len,1)\n",
        "      c=(alpha*enc_outputs).sum(dim=1) #(batch_size,num_hiddens)\n",
        "      x_and_c=torch.cat((embed_step,c),dim=1).unsqueeze(dim=1) #(batch_size,1,embed+num_hiddens)\n",
        "      out_step,state=self.rnn(x_and_c,state) #(batch_size,1,num_hiddens) (num_layers,batch_size,num_hiddens)\n",
        "      out=self.fc(out_step)  #(batch_size,1,vocab_size)\n",
        "      # output.append(out.squeeze())\n",
        "      output[:,i,:]=out.squeeze(dim=1)\n",
        "      x_step=x[:,i] #(batch_size,)\n",
        "    return output\n",
        "\n",
        "  def begin_state(self,enc_state):\n",
        "    # enc_state:(num_layers,batch_size,num_hiddens)\n",
        "    return enc_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LglBM3kvctWB",
        "colab_type": "code",
        "outputId": "c2992b6e-90d1-40c0-e607-9c477cd7874e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 测试带注意力机制的解码器\n",
        "seq_len=9\n",
        "vocab_size,embed_size,num_hiddens,num_layers,attention_size=30,10,16,2,7\n",
        "decoder=Decoder(vocab_size,embed_size,num_hiddens,num_layers,attention_size).cuda()\n",
        "state=decoder.begin_state(enc_state)\n",
        "x=torch.zeros((batch_size,seq_len)).cuda()\n",
        "output=decoder(x,state,enc_outputs)\n",
        "# print(len(output),output[0].shape)\n",
        "print(output.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 9, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MED3uPmHorwz",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.4 损失函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iydCjVqoosKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cross_loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    # real_Y:(batch_size,seq_len)\n",
        "    # output:(batch_size,seq_len,vocab_size)\n",
        "    super().__init__()\n",
        "    self.loss=nn.CrossEntropyLoss(reduction='none')\n",
        "  def forward(self,real_Y,output):\n",
        "    sum_loss,num_not_pad=0.0,0\n",
        "    for i in range(real_Y.shape[1]):\n",
        "      y=real_Y[:,i]  #(batch_size,)\n",
        "      mask=y!=torch.tensor([out_vocab.stoi[PAD]]).cuda()  #(batch_size,)\n",
        "      loss=self.loss(output[:,i,:],y.long()) #(batch_size)\n",
        "      sum_loss+=(mask*loss).sum()\n",
        "      num_not_pad+=sum(mask).item()\n",
        "    return sum_loss,num_not_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4wGcU1ooXBQ",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.5 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9SI6i1xctd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(encoder,decoder,lr,num_epochs,train_iter,loss_fn,print_every=10):\n",
        "  encoder=encoder.cuda()\n",
        "  decoder=decoder.cuda()\n",
        "  e_optimizer=optim.Adam(encoder.parameters(),lr=lr)\n",
        "  d_optimizer=optim.Adam(decoder.parameters(),lr=lr)\n",
        "\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss,sum_to_compute=0.0,0\n",
        "    for X,Y in train_iter:  #(batch_size,seq_len),(batch_size,seq_len)\n",
        "      X=X.cuda()\n",
        "      Y=Y.cuda()\n",
        "      e_optimizer.zero_grad()\n",
        "      d_optimizer.zero_grad()\n",
        "      enc_state=encoder.begin_state()\n",
        "      enc_outputs,enc_state=encoder(X,enc_state) #(batch_size,seq_len,num_hiddens),(num_layers,batch_size,num_hiddens)\n",
        "\n",
        "      dec_state=decoder.begin_state(enc_state)  #(batch_size,num_hiddens)\n",
        "      output=decoder(Y,dec_state,enc_outputs) #(batch_size,seq_len,vocab_size)\n",
        "\n",
        "      loss,num_not_pad=loss_fn(Y,output)\n",
        "\n",
        "      loss.backward()\n",
        "      e_optimizer.step()\n",
        "      d_optimizer.step()\n",
        "\n",
        "      sum_to_compute+=num_not_pad\n",
        "      train_loss+=loss.item()\n",
        "    if (epoch+1)%print_every==0:\n",
        "      print('Epoch:{} | Loss:{}'.format(epoch+1,train_loss/sum_to_compute))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGUq4Al8wQ4e",
        "colab_type": "code",
        "outputId": "3de37f2f-a183-4be2-dc3b-3dd6ba991244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "batch_size=2\n",
        "train_iter=Data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
        "embed_size,num_hiddens,num_layers,attention_size=16,16,2,10\n",
        "encoder=Encoder(len(in_vocab),embed_size,num_hiddens,num_layers)\n",
        "decoder=Decoder(len(out_vocab),embed_size,num_hiddens,num_layers,attention_size)\n",
        "loss_fn=cross_loss()\n",
        "num_epochs,lr=200,0.003\n",
        "train(encoder,decoder,lr,num_epochs,train_iter,loss_fn)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:10 | Loss:1.9978419019464861\n",
            "Epoch:20 | Loss:1.370218561406721\n",
            "Epoch:30 | Loss:1.0945608448563962\n",
            "Epoch:40 | Loss:0.9123836985805578\n",
            "Epoch:50 | Loss:0.8233084344027335\n",
            "Epoch:60 | Loss:0.6963301666995936\n",
            "Epoch:70 | Loss:0.6384744895131964\n",
            "Epoch:80 | Loss:0.5627626745324386\n",
            "Epoch:90 | Loss:0.52522873878479\n",
            "Epoch:100 | Loss:0.4579703975142094\n",
            "Epoch:110 | Loss:0.4482660962824236\n",
            "Epoch:120 | Loss:0.387531506387811\n",
            "Epoch:130 | Loss:0.3505792722367404\n",
            "Epoch:140 | Loss:0.34979275234958584\n",
            "Epoch:150 | Loss:0.3206354191428737\n",
            "Epoch:160 | Loss:0.3142714416771604\n",
            "Epoch:170 | Loss:0.31412462184303686\n",
            "Epoch:180 | Loss:0.2946873380426775\n",
            "Epoch:190 | Loss:0.27587059924477025\n",
            "Epoch:200 | Loss:0.26231403936419573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZfsPVUp2n1a",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.6 预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMPtkP2b2nbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(in_line,encoder,decoder,max_in_len,max_out_len):\n",
        "  in_tokens=in_line.rstrip().split(' ')\n",
        "  in_tokens+=[EOS]+[PAD]*(max_in_len-1-len(in_tokens))\n",
        "  corpus=torch.tensor([in_vocab.stoi[w] for w in in_tokens]).unsqueeze(dim=0).cuda() #(1,seq_len)\n",
        "  with torch.no_grad():\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    enc_state=encoder.begin_state()\n",
        "    enc_outputs,enc_state=encoder(corpus,enc_state) #(1,seq_len,num_hiddens),(num_layers,1,num_hiddens)\n",
        "\n",
        "    dec_state=decoder.begin_state(enc_state)  #(2,1,num_hiddens)\n",
        "    # output=decoder.predict(max_out_len,dec_state,enc_outputs) #(1,seq_len,vocab_size)\n",
        "\n",
        "\n",
        "    # x:(batch_size,seq_len)\n",
        "    # state:(num_layers,batch_size,num_hiddens)\n",
        "    # enc_outputs:(batch_size,seq_len,num_hiddens)\n",
        "    output=torch.zeros((1,max_out_len,decoder.vocab_size)).cuda()\n",
        "    x_step=torch.tensor([out_vocab.stoi[BOS]]).cuda() #(batch_size,)\n",
        "    for i in range(max_out_len):\n",
        "      embed_step=decoder.embedding(x_step.long())  #(batch_size,embed_size)\n",
        "      h=dec_state[-1]  #(batch_size,num_hiddens)\n",
        "      h_expand=h.unsqueeze(dim=1).expand_as(enc_outputs) #(batch_size,seq_len,num_hiddens)\n",
        "      enc_and_h=torch.cat((enc_outputs,h_expand),dim=2) #(batch_size,seq_len,2*num_hiddens)\n",
        "      alpha=F.softmax(decoder.attention(enc_and_h),dim=1) #(batch_size,seq_len,1)\n",
        "      c=(alpha*enc_outputs).sum(dim=1) #(batch_size,num_hiddens)\n",
        "      x_and_c=torch.cat((embed_step,c),dim=1).unsqueeze(dim=1) #(batch_size,1,embed+num_hiddens)\n",
        "      out_step,dec_state=decoder.rnn(x_and_c,dec_state) #(batch_size,1,num_hiddens) (num_layers,batch_size,num_hiddens)\n",
        "      out=decoder.fc(out_step)  #(batch_size,1,vocab_size)\n",
        "      # output.append(out.squeeze())\n",
        "      output[:,i,:]=out.squeeze(dim=1)\n",
        "      x_step=out.argmax(dim=2).squeeze(dim=1) #(batch_size,)\n",
        "  pred=output.argmax(dim=2)  #(1,seq_len)\n",
        "  pred_tokens=[out_vocab.itos[int(idx.item())] for idx in pred[0]]\n",
        "  out=[]\n",
        "  for w in pred_tokens:\n",
        "    if w==EOS:\n",
        "      break\n",
        "    else:\n",
        "      out.append(w)\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3VG4eBY5hq4",
        "colab_type": "code",
        "outputId": "9e3a15b5-bcca-4bcb-fa60-a229f14e8a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "in_line='ils regardent .'\n",
        "predict(in_line,encoder,decoder,max_in_len,max_out_len)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['they', 'are', 'watching', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COZrmxt1Y7Hb",
        "colab_type": "text"
      },
      "source": [
        "> 注意：在进行预测的时候代码中要加上：with tprch.no_grad() 和 encoder.eval(),decoder.eval()，否则多次运行预测代码，相同输入会导致不同输出。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK2VLW7AYeDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2ad2bc7-3c97-4b19-97ad-b124c11ad2ab"
      },
      "source": [
        "in_line='elle est vieille .'\n",
        "predict(in_line,encoder,decoder,max_in_len,max_out_len)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she', 'is', 'quiet', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iearnBwZOOZ",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.7 评价BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQhTWaKZNv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bleu(pred,real):\n",
        "  import math\n",
        "  c=len(pred)\n",
        "  real_list=real.rstrip().split()\n",
        "  r=len(real_list)\n",
        "  BP=1 if c>r else math.exp(1-r/c)\n",
        "  num_right=0\n",
        "  for w in pred:\n",
        "    if w in real_list:\n",
        "      num_right+=1\n",
        "  Precision=num_right/c\n",
        "  bleu=BP*Precision\n",
        "  return bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAD5ANPNbJI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d7e329a5-25ea-42af-a8ba-ddb9e2072fd0"
      },
      "source": [
        "# 使用bleu进行评价\n",
        "in_line='elle est vieille .'\n",
        "pred=predict(in_line,encoder,decoder,max_in_len,max_out_len)\n",
        "real='she is old .'\n",
        "print(pred,bleu(pred,real))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['she', 'is', 'quiet', '.'] 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i2f4z473ayU",
        "colab_type": "text"
      },
      "source": [
        "# 2 使用Hongyi_Li数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9K-UsQUc9nR",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 自己实现作业"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcSOemlwdGsv",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 读取并处理数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH-Fh8im38m7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "680318a1-e8a9-4876-f2d9-03b577cc03dd"
      },
      "source": [
        "Li_root='drive/My Drive/Colab Notebooks/Hongyi_Li/data'\n",
        "!gdown --id '1r4px0i-NcrnXy1-tkBsIwvYwbWnxAhcg' --output '{Li_root}/seq2seq_data.tar.gz'\n",
        "!tar -zxvf '{Li_root}/seq2seq_data.tar.gz'"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1r4px0i-NcrnXy1-tkBsIwvYwbWnxAhcg\n",
            "To: /content/drive/My Drive/Colab Notebooks/Hongyi_Li/data/seq2seq_data.tar.gz\n",
            "5.83MB [00:00, 90.4MB/s]\n",
            "cmn-eng/\n",
            "cmn-eng/int2word_cn.json\n",
            "cmn-eng/int2word_en.json\n",
            "cmn-eng/preprocess/\n",
            "cmn-eng/preprocess/build_dataset.py\n",
            "cmn-eng/preprocess/build_dictionary.sh\n",
            "cmn-eng/preprocess/cmn.txt\n",
            "cmn-eng/preprocess/cn.txt\n",
            "cmn-eng/preprocess/dict.txt.big\n",
            "cmn-eng/preprocess/dict.txt.small\n",
            "cmn-eng/preprocess/en.txt\n",
            "cmn-eng/preprocess/en_code.txt\n",
            "cmn-eng/preprocess/en_refine.txt\n",
            "cmn-eng/preprocess/en_vocab.txt\n",
            "cmn-eng/preprocess/tokenizer.py\n",
            "cmn-eng/testing.txt\n",
            "cmn-eng/training.txt\n",
            "cmn-eng/validation.txt\n",
            "cmn-eng/word2int_cn.json\n",
            "cmn-eng/word2int_en.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz5kpk3TdpFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file='./cmn-eng/training.txt'\n",
        "valid_file='./cmn-eng/validation.txt'\n",
        "test_file='./cmn-eng/testing.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dEAzggQhWFh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1d09cec3-5c27-4efb-8aa7-95e56edf4315"
      },
      "source": [
        "in_lines,out_lines,in_tokens,out_tokens,max_in_len,max_out_len=get_data(train_file)\n",
        "print(in_lines[0],out_lines[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['it', \"'s\", 'none', 'of', 'your', 'concern', '.', '', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'] ['這不關', '你', '的', '事', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr359BCChgmy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f814c76-cc21-427b-b3f8-d6f3c63a881d"
      },
      "source": [
        "# 创建字典\n",
        "in_vocab=Vocab.Vocab(collections.Counter(in_tokens),specials=[EOS,BOS,PAD])\n",
        "out_vocab=Vocab.Vocab(collections.Counter(out_tokens),specials=[EOS,BOS,PAD])\n",
        "print(len(in_vocab),len(out_vocab))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4404 9949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "933BK97kiJCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "ce4cbb0a-2e86-484a-ca7d-a72ab8d0119c"
      },
      "source": [
        "# 将句子转为corpus\n",
        "in_corpus,out_corpus=get_corpus(in_lines,out_lines,in_vocab,out_vocab)\n",
        "print(in_corpus.shape,out_corpus.shape,in_corpus[0],out_corpus[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([18000, 32]) torch.Size([18000, 26]) tensor([  16,   18,  861,   19,   32, 2039,    4,    3,    0,    2,    2,    2,\n",
            "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "           2,    2,    2,    2,    2,    2,    2,    2]) tensor([4544,    7,    5,   63,    3,    0,    2,    2,    2,    2,    2,    2,\n",
            "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "           2,    2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1be6GIzyiTly",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "37c574f3-b53e-4a47-ad74-80bcf62f7a44"
      },
      "source": [
        "# 建立数据集\n",
        "dataset=Data.TensorDataset(in_corpus,out_corpus)\n",
        "dataset[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  16,   18,  861,   19,   32, 2039,    4,    3,    0,    2,    2,    2,\n",
              "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
              "            2,    2,    2,    2,    2,    2,    2,    2]),\n",
              " tensor([4544,    7,    5,   63,    3,    0,    2,    2,    2,    2,    2,    2,\n",
              "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
              "            2,    2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYW3Bk6UilDk",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l99PXHjFidsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "0460bcd6-1efc-4485-af5a-049ff1bff812"
      },
      "source": [
        "batch_size=150\n",
        "train_iter=Data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
        "embed_size,num_hiddens,num_layers,attention_size=100,64,2,30\n",
        "encoder=Encoder(len(in_vocab),embed_size,num_hiddens,num_layers)\n",
        "decoder=Decoder(len(out_vocab),embed_size,num_hiddens,num_layers,attention_size)\n",
        "loss_fn=cross_loss()\n",
        "num_epochs,lr=20,0.003\n",
        "train(encoder,decoder,lr,num_epochs,train_iter,loss_fn,print_every=1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1 | Loss:5.714402944493042\n",
            "Epoch:2 | Loss:4.911403534971058\n",
            "Epoch:3 | Loss:4.563551391723723\n",
            "Epoch:4 | Loss:4.309564571819631\n",
            "Epoch:5 | Loss:4.1036216816969135\n",
            "Epoch:6 | Loss:3.923650357256636\n",
            "Epoch:7 | Loss:3.759410717015689\n",
            "Epoch:8 | Loss:3.608635410184233\n",
            "Epoch:9 | Loss:3.4703566909348744\n",
            "Epoch:11 | Loss:3.231262918464312\n",
            "Epoch:12 | Loss:3.1273974740500154\n",
            "Epoch:13 | Loss:3.0266089341241846\n",
            "Epoch:14 | Loss:2.938236445272846\n",
            "Epoch:15 | Loss:2.8496086191847647\n",
            "Epoch:16 | Loss:2.770799174000113\n",
            "Epoch:17 | Loss:2.6953737122455173\n",
            "Epoch:18 | Loss:2.6235850066590487\n",
            "Epoch:19 | Loss:2.5608888374512677\n",
            "Epoch:20 | Loss:2.4960548272730874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZBo5k9sms6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d157e989-a248-488d-805d-7f6b2b713eb3"
      },
      "source": [
        "in_line='he is a teacher .'\n",
        "pred=predict(in_line,encoder,decoder,max_in_len,max_out_len)\n",
        "real='他 是 老师 。'\n",
        "print(pred,bleu(pred,real))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['他', '是', '個', '好人', '。'] 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68HcrzgIpykz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}