{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skip_gram.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOab+F7IBniZfEd9Ba55/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhihong1224/RNN_demo/blob/master/skip_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHGw_nLQ-twi",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEm6QFOh-pJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch \n",
        "from torch import nn,optim\n",
        "import random\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from collections import Counter\n",
        "import torch.nn.functional as F\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAYqU9CW_hwh",
        "colab_type": "code",
        "outputId": "cd7853b4-8ee2-4551-8924-eefeab4b9e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from  google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8-6RruW_6ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT='gdrive/My Drive/Colab Notebooks/MXNet/MX_data/ptb'\n",
        "train_file=os.path.join(ROOT,'ptb.train.txt')\n",
        "test_file=os.path.join(ROOT,'ptb.test.txt')\n",
        "valid_file=os.path.join(ROOT,'ptb.valid.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0haC9W-A3SE",
        "colab_type": "text"
      },
      "source": [
        "# 读取及处理数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSv3CEuhDdxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(file):\n",
        "  with open(file) as f:\n",
        "    text=f.readlines()\n",
        "  result,token=[],[]\n",
        "  for line in text:\n",
        "    line_token=line.lower().strip().split()\n",
        "    result.append(line_token)\n",
        "    token.extend(line_token)\n",
        "  return result,token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6XIVPbIDso5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data,token=tokenize(train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77ddv09XD5SI",
        "colab_type": "code",
        "outputId": "d6bd3d8c-a331-44ff-9b8f-96a3462eada6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW3oTlDDD8gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 建立词典\n",
        "def word_idx(token):\n",
        "  counter=Counter(token)\n",
        "  word_count=dict(filter(lambda x:x[1]>=5,counter.items()))\n",
        "  idx_to_char=[ch for ch,_ in word_count.items()]\n",
        "  char_to_idx={ch:idx for idx,ch in enumerate(idx_to_char)}\n",
        "  vocab_size=len(idx_to_char)\n",
        "  word_count=np.array([count for _,count in word_count.items()])\n",
        "  word_freq=word_count/np.sum(word_count)\n",
        "  return idx_to_char,char_to_idx,vocab_size,word_freq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01DjOG4bEwzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_to_char,char_to_idx,vocab_size,word_freq=word_idx(token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01zDPiWOE24z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将文本转换为数字表示\n",
        "def get_corpus(data,char_to_idx,idx_to_char):\n",
        "  result=[]\n",
        "  for line in data:\n",
        "    result.append([char_to_idx[ch] for ch in line if ch in char_to_idx])\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fjj5OsIG7b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_corpus=get_corpus(train_data,char_to_idx,idx_to_char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M4ugcZNHH_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1b18082-e6ad-42f2-f5af-c9a14f9ea0c8"
      },
      "source": [
        "num_tokens=sum([len(st) for st in train_corpus]);num_tokens"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "887100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhRM69xKIEqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 二次采样\n",
        "def subsampling(corpus,word_freq):\n",
        "  result=[]\n",
        "  for line in corpus:\n",
        "    temp=[]\n",
        "    for idx in line:\n",
        "      if 1-np.sqrt(1e-4/word_freq[idx])<np.random.uniform(0,1):\n",
        "        temp.extend([idx])\n",
        "    result.append(temp)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO_fAZMRI55i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subsampled_corpus=subsampling(train_corpus,word_freq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8odjuWYTJ56W",
        "colab_type": "code",
        "outputId": "4ec47407-ef40-48be-9b86-afb59cbb74c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sum([len(st) for st in subsampled_corpus])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "376245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_nYDxS0KZmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 比较一个词在二次采样前后出现的次数\n",
        "def compare_count(word,char_to_idx,corpus,subsampled_corpus):\n",
        "  before_count=sum([line.count(char_to_idx[word]) for line in corpus])\n",
        "  after_count=sum([line.count(char_to_idx[word]) for line in subsampled_corpus])\n",
        "  print('before_count:{},after_count:{}'.format(before_count,after_count))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XodzFF95LhKL",
        "colab_type": "code",
        "outputId": "0407fb2a-56c3-400b-a6ef-b49db875d84b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "compare_count('the',char_to_idx,train_corpus,subsampled_corpus)\n",
        "compare_count('join',char_to_idx,train_corpus,subsampled_corpus)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before_count:50770,after_count:2043\n",
            "before_count:45,after_count:45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KmpMwLjLxf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 提取中心词、背景词\n",
        "def get_centers_contents(subsampled_corpus,max_win=5):\n",
        "  centers=[]\n",
        "  contents=[]\n",
        "  for h,line in enumerate(subsampled_corpus):\n",
        "    if len(line)<2:\n",
        "      continue\n",
        "    for idx,center in enumerate(line):\n",
        "      win_size=random.randint(1,max_win)\n",
        "      centers.extend([center]) # 中心词列表\n",
        "      indices=list(range(max(0,idx-win_size),min(len(line),idx+win_size+1)))\n",
        "      indices.remove(idx)\n",
        "      content=[line[index] for index in indices]  # 背景词\n",
        "      contents.append(content)   # 背景词列表\n",
        "  return centers,contents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAxjUT44Ucmy",
        "colab_type": "code",
        "outputId": "dab58ab5-9ebb-4b04-a782-5c08b9ffe9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# 测试中心词，背景词提取\n",
        "tiny_dataset=[list(range(7)),list(range(7,10))]\n",
        "print(tiny_dataset)\n",
        "centers,contents=get_centers_contents(tiny_dataset,max_win=2)\n",
        "print('centers:{},\\ncontens:{}\\n'.format(centers,contents))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
            "centers:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
            "contens:[[1], [0, 2], [1, 3], [2, 4], [2, 3, 5, 6], [4, 6], [5], [8, 9], [7, 9], [8]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT6yLKogRJn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_centers,all_contents=get_centers_contents(subsampled_corpus,max_win=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve_h6xJqtUKE",
        "colab_type": "code",
        "outputId": "ec5c01a8-8c58-43e5-a0c0-81209c6ec054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max([len(c) for c in all_contents]);len(all_contents)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375342"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPVD7iNocpMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 提取负例词（此函数运行效率低下）\n",
        "def get_negatives(centers,contents,vocab_size,word_freq,K=5):\n",
        "  negatives=[]\n",
        "  for i in range(len(centers)):\n",
        "    print('i',i)\n",
        "    neg_num=K*len(contents[i])  # 负例词个数\n",
        "    prob_idx=random.choices(list(range(vocab_size)),word_freq**0.75,k=200) # 候选负例词索引\n",
        "    negative=[]\n",
        "    neg_count=0\n",
        "    for prob_neg in prob_idx:\n",
        "      if prob_neg not in set(contents[i]):\n",
        "        negative.extend([prob_neg])   # 负例词索引\n",
        "        neg_count=neg_count+1\n",
        "        if neg_count==neg_num:\n",
        "          break\n",
        "      else:\n",
        "        continue\n",
        "    negatives.append(negative)   # 负例词列表\n",
        "\n",
        "  return negatives"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8vX4lMJdwnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 测试负例词\n",
        "negatives=get_negatives(centers,contents,vocab_size,word_freq)\n",
        "max([len(n) for n in negatives])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAdh1SnUeKxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_negatives=get_negatives(all_centers,all_contents,vocab_size,word_freq,K=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7CbBzz5TZ4R",
        "colab_type": "code",
        "outputId": "3b2d2186-542b-428d-d50a-f62d7a4ba355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(all_centers),len(all_contents[0]),len(all_negatives[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375342 2 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTPztToSXc_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 数据集\n",
        "class Data(Dataset):\n",
        "  def __init__(self,all_centers,all_contents,all_negatives):\n",
        "    self.all_centers=all_centers\n",
        "    self.all_contents=all_contents\n",
        "    self.all_negatives=all_negatives\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.all_centers)\n",
        "\n",
        "  def __getitem__(self,item):\n",
        "    return (self.all_centers[item],self.all_contents[item],self.all_negatives[item])\n",
        "\n",
        "def batchify(data):\n",
        "  max_content=max([len(c) for _,c,n in data])\n",
        "  max_negative=max([len(n) for _,c,n in data])\n",
        "  centers,contents,negatives=[],[],[]\n",
        "  mask_contents,mask_negatives=[],[]\n",
        "  for center,content,negative in data:\n",
        "    centers.extend([center])\n",
        "    contents.append(content+[0]*(max_content-len(content)))\n",
        "    negatives.append(negative+[0]*(max_negative-len(negative)))\n",
        "    mask_contents.append([1]*len(content)+[0]*(max_content-len(content)))\n",
        "    mask_negatives.append([1]*len(negative)+[0]*(max_negative-len(negative)))\n",
        "  return (torch.tensor(centers).view(-1,1),torch.tensor(contents),torch.tensor(negatives),torch.tensor(mask_contents),torch.tensor(mask_negatives))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Yi5i_wjjcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=Data(all_centers,all_contents,all_negatives)\n",
        "batch_size=512\n",
        "train_iter=DataLoader(dataset,batch_size=batch_size,shuffle=True,collate_fn=batchify)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k98fq0rk5gJ",
        "colab_type": "code",
        "outputId": "6e6d2ec9-db0e-4e40-fe58-3e6cf1101a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "for batch in train_iter:\n",
        "  for name,data in zip(['centers','contents','negatives','mask_contents','mask_negatives'],batch):\n",
        "    print(name,' shape:',data.shape)\n",
        "  break"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "centers  shape: torch.Size([512, 1])\n",
            "contents  shape: torch.Size([512, 10])\n",
            "negatives  shape: torch.Size([512, 50])\n",
            "mask_contents  shape: torch.Size([512, 10])\n",
            "mask_negatives  shape: torch.Size([512, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "detdN5jZoaHc",
        "colab_type": "text"
      },
      "source": [
        "# 模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGEfEWRklL-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_size):\n",
        "    super(Net,self).__init__()\n",
        "    self.in_embed=nn.Embedding(vocab_size,embed_size)\n",
        "    self.out_embed=nn.Embedding(vocab_size,embed_size)\n",
        "  def forward(self,centers,contents,negatives,mask_contents,mask_negatives):\n",
        "    # centers:(batch_size,1)\n",
        "    # contents:(batch_size,max_c)\n",
        "    # negatives:(batch_size,max_n)\n",
        "    # mask_contents:(batch_size,max_c)\n",
        "    # mask_negatives:(batch_size,max_n)\n",
        "    centers_embed=self.in_embed(centers)    # (batch_size,1,embed_size)\n",
        "    contents_embed=self.out_embed(contents)   # (batch_size,max_c,embed_size)\n",
        "    negatives_embed=self.out_embed(negatives)  # (batch_size,max_n,embed_size) \n",
        "    sim_cc=torch.bmm(contents_embed,centers_embed.permute(0,2,1)) # (batch_size,max_c,1)\n",
        "    sim_cn=torch.bmm(negatives_embed,centers_embed.permute(0,2,1)) #(batch_size,max_n,1)\n",
        "    sim_cc=sim_cc.squeeze(-1)  # (batch_size,max_c)\n",
        "    sim_cn=sim_cn.squeeze(-1)  # (batch_size,max_n)\n",
        "    sim_cc=sim_cc*mask_contents\n",
        "    sim_cn=sim_cn*mask_negatives \n",
        "    loss=-F.logsigmoid(sim_cc).sum(1)-F.logsigmoid(-sim_cn).sum(1)\n",
        "    return loss\n",
        "class Loss_fn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Loss_fn,self).__init__()\n",
        "  def forward(self,sim_cc,sim_cn):\n",
        "    return -torch.log(torch.sigmoid(sim_cc)).sum(dim=1)-torch.log(1-torch.sigmoid(sim_cn)).sum(dim=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlTdatf6yMXG",
        "colab_type": "text"
      },
      "source": [
        "# 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC2YW3hFyNke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,Loss_fn,num_epochs,lr,train_iter):\n",
        "  model=model.to(device)\n",
        "  criterion=Loss_fn()\n",
        "  optimizer=optim.Adam(model.parameters(),lr=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss,n=0.0,0\n",
        "    for centers,contents,negatives,mask_contents,mask_negatives in train_iter:\n",
        "      centers=centers.to(device)\n",
        "      contents=contents.to(device)\n",
        "      negatives=negatives.to(device)\n",
        "      mask_contents=mask_contents.to(device)\n",
        "      mask_negatives=mask_negatives.to(device)\n",
        "      loss=model(centers,contents,negatives,mask_contents,mask_negatives).mean()\n",
        "      # loss=criterion(sim_cc,sim_cn).sum()\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss+=loss.item()\n",
        "      n+=1\n",
        "    train_loss=train_loss/(n*60)\n",
        "    print('epoch:{},train loss:{}'.format(epoch+1,train_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AukbWbsufita",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "a93dce19-f640-4df5-d2f0-dd8830fe1630"
      },
      "source": [
        "model=Net(vocab_size,100)\n",
        "num_epochs,lr=10,0.01\n",
        "train(model,Loss_fn,num_epochs,lr,train_iter)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train loss:1.2155407589419553\n",
            "epoch:2,train loss:0.6503230510680487\n",
            "epoch:3,train loss:0.581870673722727\n",
            "epoch:4,train loss:0.560213195703768\n",
            "epoch:5,train loss:0.5501134004948033\n",
            "epoch:6,train loss:0.5440090482609582\n",
            "epoch:7,train loss:0.5393522541486166\n",
            "epoch:8,train loss:0.5354487695875869\n",
            "epoch:9,train loss:0.5321821521565007\n",
            "epoch:10,train loss:0.5292974558664819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HVgsoBI6ouc",
        "colab_type": "text"
      },
      "source": [
        "# 应用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKBpGxPd6qFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "134264cd-ca38-4450-904e-c646ce2b7e24"
      },
      "source": [
        "def get_similar_tokens(query_token,k,model):\n",
        "  W=model.in_embed.weight.data\n",
        "  x=W[char_to_idx[query_token]]\n",
        "  cos=torch.matmul(W,x)/(torch.sum(W*W,dim=1)*torch.sum(x*x)+1e-9).sqrt()\n",
        "  _,topk=torch.topk(cos,k=k+1)\n",
        "  topk=topk.cpu().numpy()\n",
        "  for i in topk[1:]:\n",
        "    print('cosine sim=%.3f:%s'%(cos[i],(idx_to_char[i])))\n",
        "get_similar_tokens('chip',3,model)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.570:intel\n",
            "cosine sim=0.541:microprocessor\n",
            "cosine sim=0.507:computer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnHJvH_wlkrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}