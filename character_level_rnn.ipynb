{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取及处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/anna.txt','r') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "idx_to_char=list(set(text))\n",
    "char_to_idx={ch:idx for idx,ch in enumerate(idx_to_char)}\n",
    "vocab_size=len(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 'a')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx['i'],idx_to_char[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus\n",
    "corpus=[char_to_idx[i] for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([59, 29, 63, 4, 27, 7, 33, 68, 41, 44], 1985223)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10],len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minibatches\n",
    "def get_batches(corpus,batch_size,num_steps,device):\n",
    "    batch_len=len(corpus)//batch_size\n",
    "    batch_num=(batch_len-1)//num_steps\n",
    "    corpus=np.array(corpus)   \n",
    "    batch_data=corpus[:batch_size*batch_len].reshape(batch_size,batch_len)\n",
    "    for i in range(batch_num):\n",
    "        x=batch_data[:,i*num_steps:(i+1)*num_steps]\n",
    "        y=batch_data[:,i*num_steps+1:(i+1)*num_steps+1]\n",
    "        yield torch.tensor(x,dtype=torch.float32,device=device),\\\n",
    "        torch.tensor(y,dtype=torch.float32,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([3, 4])\n",
      "torch.Size([3, 4]) torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# minibatches 测试\n",
    "test_seq=range(30)\n",
    "test_batches=get_batches(test_seq,3,4,device)\n",
    "for x,y in test_batches:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot 表示\n",
    "def one_hot(x,vocab_size):\n",
    "    # x:(batch_size,num_steps)\n",
    "    # out:(batch_size,num_steps,vocab_size)\n",
    "    bs,ns=x.shape\n",
    "    out=torch.zeros((bs,ns,vocab_size),dtype=torch.float32,device=x.device)\n",
    "    for i in range(bs):\n",
    "        for j in range(ns):\n",
    "            out[i,j,int(x[i,j])]=1.\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_hot 测试\n",
    "x=torch.tensor([[2,4,1],[1,2,3]])\n",
    "out=one_hot(x,5);out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将corpus划分为minibatches\n",
    "batch_size,num_steps=8,50\n",
    "mini_batches=get_batches(corpus,batch_size,num_steps,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 50]) torch.Size([8, 50])\n"
     ]
    }
   ],
   "source": [
    "for X,Y in mini_batches:\n",
    "    print(X.shape,Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,vocab_size,num_hiddens,num_layers,drop_prob):\n",
    "        super(Net,self).__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.num_hiddens=num_hiddens\n",
    "        self.lstm=nn.LSTM(vocab_size,num_hiddens,num_layers,dropout=drop_prob,batch_first=True)\n",
    "        self.dropout=nn.Dropout(p=drop_prob)\n",
    "        self.fc=nn.Linear(num_hiddens,vocab_size)\n",
    "        self.num_layers=num_layers\n",
    "    def forward(self,x,hidden):\n",
    "        # x:(batch_size,num_steps)\n",
    "        x=one_hot(x,self.vocab_size)\n",
    "        temp,hidden=self.lstm(x,hidden)\n",
    "        temp=self.dropout(temp)   #(batch_size,num_steps,num_hiddens)\n",
    "        temp=temp.contiguous().view(-1,self.num_hiddens)  #(batch_size*num_steps,num_hiddens)\n",
    "        out=self.fc(temp)\n",
    "        return out,hidden\n",
    "    def init_state(self,batch_size):\n",
    "        weight=next(self.parameters()).data\n",
    "        hidden=(weight.new(self.num_layers,batch_size,self.num_hiddens).zero_().cuda(),\n",
    "               weight.new(self.num_layers,batch_size,self.num_hiddens).zero_().cuda())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio=0.2\n",
    "L=len(corpus)\n",
    "valid_num=int(L*valid_ratio)\n",
    "valid_corpus=corpus[:valid_num]\n",
    "train_corpus=corpus[valid_num:]\n",
    "batch_size=128\n",
    "num_steps=100\n",
    "# train_iter=get_batches(train_corpus,batch_size,num_steps,device)\n",
    "# valid_iter=get_batches(valid_corpus,batch_size,num_steps,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(Dataset):\n",
    "    def __init__(self,corpus,batch_size,num_steps):\n",
    "        self.corpus=corpus\n",
    "        batch_len=len(corpus)//batch_size\n",
    "        batch_num=(batch_len-1)//num_steps\n",
    "        corpus=np.array(corpus)   \n",
    "        batch_data=corpus[:batch_size*batch_len].reshape(batch_size,batch_len)\n",
    "        self.batch_data=batch_data\n",
    "        self.batch_num=batch_num\n",
    "        self.num_steps=num_steps\n",
    "    def __len__(self):\n",
    "        return self.batch_num\n",
    "    def __getitem__(self,idx):\n",
    "        x=self.batch_data[:,idx*self.num_steps:(idx+1)*self.num_steps]\n",
    "        y=self.batch_data[:,idx*self.num_steps+1:(idx+1)*self.num_steps+1]\n",
    "        return x,y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=Corpus(train_corpus,batch_size,num_steps)\n",
    "valid_data=Corpus(valid_corpus,batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter=DataLoader(train_data,batch_size=1)\n",
    "valid_iter=DataLoader(valid_data,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 100]) torch.Size([1, 128, 100])\n"
     ]
    }
   ],
   "source": [
    "for X,Y in valid_iter:\n",
    "    print(X.shape,Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 31)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l_train=sum(1 for _ in train_iter)\n",
    "# l_valid=sum(1 for _ in valid_iter)\n",
    "# l_train,l_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,num_epochs,lr,train_iter,valid_iter,clip=5):\n",
    "    model=model.to(device)\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.Adam(model.parameters(),lr=lr)\n",
    "    valid_min_loss=np.inf\n",
    "    train_loss_list,valid_loss_list=[],[]\n",
    "    for epoch in range(num_epochs):\n",
    "#         train_iter=get_batches(train_corpus,batch_size,num_steps,device)\n",
    "#         valid_iter=get_batches(valid_corpus,batch_size,num_steps,device)\n",
    "        model.train()\n",
    "        train_loss,valid_loss=0.0,0.0\n",
    "        hidden=model.init_state(batch_size)\n",
    "        for X,Y in train_iter:\n",
    "            # X:(batch_size,num_steps)\n",
    "            # Y:(batch_size,num_steps)\n",
    "            X=X.squeeze(0).to(device)\n",
    "            Y=Y.squeeze(0).to(device)\n",
    "            y_pred,hidden=model(X,hidden)  # (batch_size*num_steps,vocab_size)\n",
    "            hidden=(hidden[0].detach(),hidden[1].detach())\n",
    "            loss=criterion(y_pred,Y.view(-1).long())\n",
    "            print(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()*Y.shape[0]*Y.shape[1]\n",
    "            train_loss_list.append(loss.item())\n",
    "        model.eval()\n",
    "        hidden=model.init_state(batch_size)\n",
    "        with torch.no_grad():\n",
    "            for X,Y in valid_iter:\n",
    "                X=X.squeeze(0).to(device)\n",
    "                Y=Y.squeeze(0).to(device)\n",
    "                y_pred,hidden=model(X,hidden)\n",
    "                loss1=criterion(y_pred,Y.view(-1).long())\n",
    "                valid_loss+=loss1.item()*Y.shape[0]*Y.shape[1]\n",
    "                valid_loss_list.append(loss1.item())\n",
    "        train_loss=train_loss/(len(train_data)*batch_size*num_steps)\n",
    "        valid_loss=valid_loss/(len(valid_data)*batch_size*num_steps)\n",
    "        if valid_loss<valid_min_loss:\n",
    "            print('validation decreased {}-->{}.saving model...'.\\\n",
    "                 format(valid_min_loss,valid_loss))\n",
    "            valid_min_loss=valid_loss\n",
    "        print('epoch:{},train loss:{},valid loss:{}'.\\\n",
    "             format(epoch+1,train_loss,valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens=512\n",
    "num_layers=1\n",
    "drop_prob=0\n",
    "num_epochs=1\n",
    "lr=0.001\n",
    "model=Net(vocab_size, num_hiddens, num_layers, drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.422250270843506\n",
      "4.3940935134887695\n",
      "4.36194372177124\n",
      "4.314607620239258\n",
      "4.213876247406006\n",
      "3.4982666969299316\n",
      "3.2906057834625244\n",
      "3.210195541381836\n",
      "3.161435127258301\n",
      "3.157169818878174\n",
      "3.184666633605957\n",
      "3.173596143722534\n",
      "3.1485846042633057\n",
      "3.14168119430542\n",
      "3.1212921142578125\n",
      "3.117521047592163\n",
      "3.1341660022735596\n",
      "3.1339242458343506\n",
      "3.131324052810669\n",
      "3.1198978424072266\n",
      "3.1225481033325195\n",
      "3.1074090003967285\n",
      "3.0931224822998047\n",
      "3.093663215637207\n",
      "3.1027867794036865\n",
      "3.103619337081909\n",
      "3.0913808345794678\n",
      "3.096703290939331\n",
      "3.083831787109375\n",
      "3.086979627609253\n",
      "3.1143958568573\n",
      "3.095179796218872\n",
      "3.095350980758667\n",
      "3.077864646911621\n",
      "3.1012117862701416\n",
      "3.104846715927124\n",
      "3.1231496334075928\n",
      "3.107208251953125\n",
      "3.1028528213500977\n",
      "3.0944082736968994\n",
      "3.0917162895202637\n",
      "3.083364248275757\n",
      "3.0834827423095703\n",
      "3.078120231628418\n",
      "3.0878357887268066\n",
      "3.1052374839782715\n",
      "3.107113838195801\n",
      "3.1156508922576904\n",
      "3.115726947784424\n",
      "3.0858230590820312\n",
      "3.0871856212615967\n",
      "3.0833468437194824\n",
      "3.0884604454040527\n",
      "3.070981502532959\n",
      "3.0664424896240234\n",
      "3.0769410133361816\n",
      "3.0875890254974365\n",
      "3.077118158340454\n",
      "3.1036696434020996\n",
      "3.0873184204101562\n",
      "3.085904598236084\n",
      "3.0689327716827393\n",
      "3.0582380294799805\n",
      "3.057572841644287\n",
      "3.0829954147338867\n",
      "3.066304922103882\n",
      "3.0649471282958984\n",
      "3.0666892528533936\n",
      "3.0410492420196533\n",
      "3.0544731616973877\n",
      "3.061617851257324\n",
      "3.0649569034576416\n",
      "3.0419342517852783\n",
      "3.0366878509521484\n",
      "3.055126905441284\n",
      "3.0439157485961914\n",
      "3.0375397205352783\n",
      "3.0308034420013428\n",
      "3.0492050647735596\n",
      "3.0380349159240723\n",
      "3.0494039058685303\n",
      "3.0443472862243652\n",
      "3.0164239406585693\n",
      "3.0353643894195557\n",
      "3.0228631496429443\n",
      "3.043306589126587\n",
      "3.0208330154418945\n",
      "3.010579824447632\n",
      "3.008340358734131\n",
      "3.0137763023376465\n",
      "3.011444330215454\n",
      "2.9894800186157227\n",
      "2.987781047821045\n",
      "2.975219964981079\n",
      "2.977320671081543\n",
      "2.9798738956451416\n",
      "2.9685559272766113\n",
      "2.980254888534546\n",
      "2.9656503200531006\n",
      "2.9751453399658203\n",
      "2.967808485031128\n",
      "2.962324857711792\n",
      "2.9687345027923584\n",
      "2.9504566192626953\n",
      "2.9605038166046143\n",
      "2.9357430934906006\n",
      "2.9194064140319824\n",
      "2.9351861476898193\n",
      "2.8965468406677246\n",
      "2.8972089290618896\n",
      "2.9189023971557617\n",
      "2.906648874282837\n",
      "2.9161744117736816\n",
      "2.862575054168701\n",
      "2.8717103004455566\n",
      "2.8641786575317383\n",
      "2.8636579513549805\n",
      "2.8866889476776123\n",
      "2.8675310611724854\n",
      "2.8388824462890625\n",
      "2.8483803272247314\n",
      "2.829012393951416\n",
      "2.8346993923187256\n",
      "2.7930972576141357\n",
      "validation decreased inf-->2.817167874305479.saving model...\n",
      "epoch:1,train loss:3.095900729779274,valid loss:2.817167874305479\n"
     ]
    }
   ],
   "source": [
    "train(model,num_epochs,lr,train_iter,valid_iter)  #训练一次花费时间长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,char,hidden=None,top_k=None):\n",
    "    x=np.array([[char_to_idx[char]]])  # (1,1)\n",
    "    x=torch.tensor(x,dtype=torch.float32,device=device)  \n",
    "    hidden = tuple([each.data for each in hidden])\n",
    "    out,hidden=model(x,hidden)  # out:(1,vocab_size) \n",
    "    p=F.softmax(out,dim=1).data   #(1,vocab_size)\n",
    "    p=p.cpu()\n",
    "    if top_k is None:\n",
    "        top_ch=np.arange(vocab_size)\n",
    "    else:\n",
    "        p,top_ch=p.topk(top_k)\n",
    "        top_ch=top_ch.numpy().squeeze()\n",
    "    p=p.numpy().squeeze()\n",
    "    char=np.random.choice(top_ch,p=p/p.sum())\n",
    "    return idx_to_char[char],hidden\n",
    "\n",
    "def sample(model,size,prime='The',top_k=None):\n",
    "    model.eval()\n",
    "    chars=[ch for ch in prime]\n",
    "    hidden=model.init_state(1)\n",
    "    for ch in prime:\n",
    "        char,hidden=predict(model,ch,hidden,top_k=top_k)\n",
    "    chars.append(char)\n",
    "    for ii in range(size):\n",
    "        char,hidden=predict(model,chars[-1],hidden,top_k=top_k)\n",
    "        chars.append(char)\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And Levin saide his  eeshee tat taretho the tannd  e rot ot ei toro titethithathen ein hore thot aed hin ho ser  eo hotther and  ond oo het ardnneteerit hhe hin  eo thes horis eothis the hin hate toee the th teen hi ee sieet ae hen ho tert oe thathatitie aher het aterith  tenthann hit  toteratone  an  ere ann hor taet oasinneteetheen thin  eo tore th  on tha  th sethar an sinn he hhr aon tet horeerte so ae thene  hithethann onn ao the hen onn honneeat oonesthe soter there aer atree toret orrs ton aone  on aone  ie  or ann tor  thar sh  or  aneteete  end th sh neerasien hinn an teasithan  hit he te te  ie  int aonen and oets toee tone sirn heeritine  on hart ooet aor ahis an  oorie to to teethin ae to e toet hishe tanttaottat eoro t teesandishis hirttand hind aen tie hinn oorer ane ah tind we  hethin he hit eee to eirt hen ho to ton tent onndtherertae tot totiee hone ae thirerite  endet endeathensearet ha sir tor sirese he he shens tenthertanethireenashond he ti sh  a t tht ha se th tit  otrar aht ein\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, 1000, top_k=5, prime=\"And Levin said\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv1] *",
   "language": "python",
   "name": "conda-env-myenv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
